---
title: "The Matrix Profile"
author: STUMPY by Ameritrade

order: 1
format: revealjs
subtitle: "Fast, effective tool for timeseries."
date: "2024"

fig-cap-location: margin 
title-slide-attributes: 
    data-background-image: 'img/logos/gem_cityML_slide.png'
    data-background-size: "100% 100%"
    data-background-position: "0%"
    data-background-opacity: "0.95" 


---

## Matrix Profile

A **matrix profile** is a vector that stores the [z-normalized Euclidean distance](https://youtu.be/LnQneYvg84M?t=374) between any subsequence within a time series and its nearest neighbor.  


<br>  
<br>  

### Easy peasy
---

### Example: Time Series with Length n = 13
Let's take a step back and start with a simple illustrative example:




```python
time_series = [0, 1, 3, 2, 9, 1, 14, 15, 1, 2, 2, 10, 7]
n = len(time_series)
```


To analyze this time series with length `n = 13`, we could:

* visualize the data or
* calculate global summary statistics (i.e., mean, median, mode, min, max). 

If you had a much longer time series, then you may even feel compelled to build:

* an ARIMA model, 
* perform anomaly detection, or 
* attempt a forecasting model 

but these methods can be complicated and may often have false positives or no interpretable insights.

---

![Time Series Visualization](images/time_series_viz.jpeg)

---

If we were to apply *Occam's Razor*,  
then what is the most **simple and intuitive** approach?  

To answer this question, let's start with our definition of Matric profile.  
<br>  

*A matrix profile, a vector that stores the z-normalized Euclidean distance between any* **subsequence** *within a time series and its nearest neighbor.*  

<br>

#### Let's take a closer look at Subsequence

## Subsequence 

### a part or section of the full time series

The following are all considered subsequences of our `time_series` since they can all be found in the time series above.

--- 

![Subsequence 1](images/subsequence_a.jpeg){width=300px}
![Subsequence 2](images/subsequence_b.jpeg){width=300px}
![Subsequence 3](images/subsequence_c.jpeg){width=300px}


```python
print(time_series[0:2])
print(time_series[4:7])
print(time_series[2:10])
```

    [0, 1]
    [9, 1, 14]
    [3, 2, 9, 1, 14, 15, 1, 2]


---

Each subsequence can have a different sequence length.  
We'll call a sequence length  `m`.  
So, for example, if we choose `m = 4`, then we can think about how we might compare any two subsequences of the same length.


```python
m = 4
i = 0  # starting index for the first subsequence
j = 8  # starting index for the second subsequence

subseq_1 = time_series[i:i+m]
subseq_2 = time_series[j:j+m]

print(subseq_1, subseq_2)
```

    [0, 1, 3, 2] [1, 2, 2, 10]


![Subsequences](images/subsequences.jpeg)

---

One way to compare any two subsequences is to calculate what is called the **Euclidean distance**.  
<br>  
<br>  

### Euclidean Distance 

#### the straight-line distance between two points

## Euclidiean Distance

Take two points: (0,1,3,2) and (1,2,3,10).

![Euclidean Distance](images/euclidean_distance.jpeg){width=530px}


---

```python
import math
m = 4
i = 0  # starting index for the first subsequence
j = 8  # starting index for the second subsequence

D = 0
for k in range(m):
    D += (time_series[i+k] - time_series[j+k])**2
print(f"The square root of {D} = {math.sqrt(D)}")
```

    The square root of 67 = 8.18535277187245


## But wait, there is more

Let's take this a step further.  
Let's keep one subsequence the same (**reference subsequence**).   
Then let the second subsequence be a sliding window.  
**THEN** compute the Euclidean distance for each window!  

<br>
The resulting vector of pairwise Euclidean distances is  known as a **distance profile**.

![Pairwise Euclidean Distance](images/pairwise_euclidean_distance.gif)

## Distance Profile - Pairwise Euclidean Distances

![Pairwise Euclidean Distance](images/pairwise_euclidean_distance.gif)

## Trivial Match

Not all of these distances are useful.   

Specifically, the distance for the self match (or trivial match) isn't informative since the distance will be always be zero when you are comparing a subsequence with itself.   

--- 

### Nothing to see here

So, we'll ignore it and, instead, take note of the next smallest distance from the distance profile and choose that as our best match:

![Trivial Match](images/trivial_match.jpeg)

---

Next, we can shift our reference subsequence over one element at a time and repeat the same sliding window process to compute the distance profile for each new reference subsequence.

![Distance Profiles](images/distance_matrix.gif)

## Distance Matrix

If we take all of the distance profiles that were computed for each reference subsequence and stack them one on top of each other then we get something called a **distance matrix**.


![Distance Matrix](images/distance_matrix.jpeg)


## Matrix Profile 

Let's simplify this distance matrix.  
We will only look at the nearest neighbor for each subsequence.  

When we do this it creates a **Matrix Profile**.  

### Matrix Profile 

#### a vector that stores the [(z-normalized) Euclidean distance](https://youtu.be/LnQneYvg84M?t=374) between any subsequence within a time series and its nearest neighbor

## Matrix Profile 

Practically, what this means is that the matrix profile is only interested in storing the smallest non-trivial distances from each distance profile, which significantly reduces the spatial complexity to **O(n)**.

![Matrix Profile](images/matrix_profile.gif)

## Time Series Matrix Profile
We can now plot this matrix profile underneath our original time series. And, as it turns out, a reference subsequence with a small matrix profile value (i.e., it has a nearest neighbor significantly "closeby") may indicate a possible pattern.  
<br>

While a reference subsequence with a **large** matrix profile value (i.e., its nearest neighbor is significantly "faraway") may suggest the presence of an anomaly!  

![Time Series Matrix Profile ](images/matrix_profile.jpeg)

---

### What Matrix Profile gives out
By simply computing and inspecting the matrix profile alone, one can easily pick out the:

* top pattern (global minimum) and 
* rarest anomaly (global maximum).   

<br>
And this is only a small glimpse into what is possible once you've computed the matrix profile!

## The Brute Force Approach

Now, it might seem pretty straightforward at this point but...  
<br>

We need to do is consider how to compute the full distance matrix *efficiently*.  
Let's start with the brute force approach: 


```python
for i in range(n-m+1):
    for j in range(n-m+1):
        D = 0
        for k in range(m):
            D += (time_series[i+k] - time_series[j+k])**2
        D = math.sqrt(D)
```



At first glance, this may not look too bad but...  
<br>
if we start considering both the computational complexity as well as the spatial complexity then we begin to understand the real problem.   
It turns out that, for longer time series (i.e., *n >> 10,000*) the computational complexity is $O(n^2m)$ (as evidenced by the three for loops in the code above) and ...  

the spatial complexity for storing the full distance matrix is $O(n^2)$. 


## In Prospective

To put this into perspective, imagine if you had a single sensor that collected data 20 times/min over the course of 5 years.   
This would result:



```python
n = 20 * 60 * 24 * 364 * 5  # 20 times/min x 60 mins/hour x 24 hours/day x 365 days/year x 5 years
print(f"There would be n = {n} data points")
```

    There would be n = 52416000 data points

---

Assuming that each calculation in the inner loop takes 0.0000001 seconds then this would take:


```python
time = 0.0000001 * (n * n - n)/2
print(f"It would take {time} seconds to compute")
```

    It would take 137371850.1792 seconds to compute


Which is equivalent to 1,598.7 days (or 4.4 years) and 11.1 PB of memory to compute!   
<br>
It is **not** feasible to compute the distance matrix using our naive brute force method.  
<br>
Instead, we need to figure out how to reduce this computational complexity by efficiently generating a matrix profile and this is where *STUMPY* comes into play. 

## STUMPY

In the fall of 2016, researchers from the [University of California, Riverside](https://www.cs.ucr.edu/~eamonn) and the [University of New Mexico](https://www.cs.unm.edu/~mueen/) published a beautiful set of [back-to-back papers](https://www.cs.ucr.edu/~eamonn/MatrixProfile.html) that described an exact method called **STOMP** for computing the matrix profile for any time series with a computational complexity of $O(n^2)$!  
<br>

### STUMPY Developers
With the academics, data scientists, and developers in mind, STUMPY developers have taken these concepts and created open sourced STUMPY.  
A powerful and scalable library that efficiently computes the matrix profile according to this published research.   

And, thanks to other open source software such as [Numba](http://numba.pydata.org/) and [Dask](https://dask.org/), their implementation is highly parallelized (for a single server with multiple CPUs or, alternatively, multiple GPUs), highly distributed (with multiple CPUs across multiple servers). We've tested STUMPY on as many as 256 CPU cores (spread across 32 servers) or 16 NVIDIA GPU devices (on the same DGX-2 server) and have achieved similar [performance](https://github.com/TDAmeritrade/stumpy#performance) to the published GPU-STOMP work.

## Conclusion

According to the original authors, "these are the best ideas in times series data mining in the last two decades" and "given the matrix profile, [most time series data mining problems are trivial to solve in a few lines of code](https://www.cs.ucr.edu/~eamonn/100_Time_Series_Data_Mining_Questions__with_Answers.pdf)". 

## Resources


[STUMPY Documentation](https://stumpy.readthedocs.io/en/latest/)

[STUMPY Matrix Profile Github Code Repository](https://github.com/TDAmeritrade/stumpy)
